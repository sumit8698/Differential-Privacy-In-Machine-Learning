# -*- coding: utf-8 -*-
"""Final_project_proof.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EKnC8r6pWIYrc6nGPqj0wTyERgZIm1DS
"""

!pip install opacus
import torch
from torchvision import datasets, transforms
import numpy as np
from opacus import PrivacyEngine
from tqdm import tqdm
import matplotlib.pyplot as plt
from PIL import Image
from numpy import vstack
from numpy import argmax
from sklearn.metrics import accuracy_score


# importing training dataset which has 60,000 observation
train_loader = torch.utils.data.DataLoader(datasets.MNIST('../mnist', train=True, download=True,
                                                          transform=transforms.Compose(
                                                              [transforms.ToTensor(), transforms.Normalize((0.1307,),
                                                                                                           (
                                                                                                           0.3081,)), ]), ),
                                           batch_size=64, shuffle=True, num_workers=1, pin_memory=True)

# importing testing dataset which has 10,000 observation
test_loader = torch.utils.data.DataLoader(datasets.MNIST('../mnist', train=False,
                                                         transform=transforms.Compose(
                                                             [transforms.ToTensor(), transforms.Normalize((0.1307,),
                                                                                                          (
                                                                                                          0.3081,)), ]), ),
                                          batch_size=1024, shuffle=True, num_workers=1, pin_memory=True)

# Creating a PyTorch Neural Network Classification Model and Optimizer
model = torch.nn.Sequential(torch.nn.Conv2d(1, 16, 8, 2, padding=3), torch.nn.ReLU(), torch.nn.MaxPool2d(2, 1),
                            torch.nn.Conv2d(16, 32, 4, 2), torch.nn.ReLU(), torch.nn.MaxPool2d(2, 1),
                            torch.nn.Flatten(),
                            torch.nn.Linear(32 * 4 * 4, 32), torch.nn.ReLU(), torch.nn.Linear(32, 10))

optimizer = torch.optim.SGD(model.parameters(), lr=0.05)

# Training a model without adding a noise
def train_notprivate(model, train_loader, optimizer, epoch, device):
    model.train()
    criterion = torch.nn.CrossEntropyLoss()
    losses = []
    for _batch_idx, (data, target) in enumerate(tqdm(train_loader)):
        data, target = data.to(device), target.to(device)
        optimizer.zero_grad()
        output = model(data)
        loss = criterion(output, target)
        loss.backward()
        optimizer.step()
        losses.append(loss.item())
    print(
        f"Train Epoch: {epoch} \t"
        f"Loss: {np.mean(losses):.6f} ")

for epoch in range(1, 11):
    train_notprivate(model, train_loader, optimizer, epoch, device="cpu")

# Evaluating a model accuracy
def evaluate_model(test_dl, model):
    predictions, actuals = list(), list()
    for i, (inputs, targets) in enumerate(test_dl):
      # evaluate the model on the test set
      yhat = model(inputs)
      # retrieve numpy array
      yhat = yhat.detach().numpy()
      actual = targets.numpy()
      # convert to class labels
      yhat = argmax(yhat, axis=1)
      # reshape for stacking
      actual = actual.reshape((len(actual), 1))
      yhat = yhat.reshape((len(yhat), 1))
      # store
      predictions.append(yhat)
      actuals.append(actual)
    predictions, actuals = vstack(predictions), vstack(actuals)
    # calculate accuracy
    acc = accuracy_score(actuals, predictions)
    return acc
 

# prepare the data
train_dl, test_dl = train_loader, test_loader
print(len(train_dl.dataset), len(test_dl.dataset))
acc = evaluate_model(test_dl, model)
print('Accuracy: %.3f' % acc)

# Creating a PyTorch Neural Network Classification Model and Optimizer
DP_model = torch.nn.Sequential(torch.nn.Conv2d(1, 16, 8, 2, padding=3), torch.nn.ReLU(), torch.nn.MaxPool2d(2, 1),
                            torch.nn.Conv2d(16, 32, 4, 2), torch.nn.ReLU(), torch.nn.MaxPool2d(2, 1),
                            torch.nn.Flatten(),
                            torch.nn.Linear(32 * 4 * 4, 32), torch.nn.ReLU(), torch.nn.Linear(32, 10))

DP_optimizer = torch.optim.SGD(DP_model.parameters(), lr=0.05)

# Attaching a Differential Privacy Engine to the Optimizer
privacy_engine= PrivacyEngine()
N_model, N_optimizer, dataloader = privacy_engine.make_private(
    module=DP_model,
    optimizer=DP_optimizer,
    data_loader=train_loader,
    noise_multiplier=1.3,
    max_grad_norm=1.1,
    poisson_sampling=False,
)


def get_epsilon(self, delta):
  return self.accountant.get_epsilon(delta)
# Training the private model over multiple epochs
def train(model, train_loader, optimizer, epoch, device, delta):
    model.train()
    criterion = torch.nn.CrossEntropyLoss()
    losses = []
    for _batch_idx, (data, target) in enumerate(tqdm(train_loader)):
        data, target = data.to(device), target.to(device)
        optimizer.zero_grad()
        output = model(data)
        loss = criterion(output, target)
        loss.backward()
        optimizer.step()
        losses.append(loss.item())
    epsilon=privacy_engine.get_epsilon(delta)
    print(
        f"Train Epoch: {epoch} \t"
        f"Loss: {np.mean(losses):.6f} "
        f"(ε = {epsilon:.2f}, δ = {delta})")

for epoch in range(1, 11):
    train(N_model, dataloader, N_optimizer, epoch, device="cpu", delta=1e-5)

acc = evaluate_model(test_loader, N_model)
print('Accuracy: %.3f' % acc)

dataloader.batch_size
examples = enumerate(dataloader)
batch_idx, (example_data, example_targets) = next(examples)

fig = plt.figure()
for i in range(6):
  plt.subplot(2,3,i+1)
  plt.tight_layout()
  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')
  plt.title("Ground Truth: {}".format(example_targets[i]))
  plt.xticks([])
  plt.yticks([])
fig

print(N_model)
model_child = list(N_model.children())

import torch.nn as nn
no_of_layers=0
conv_layers=[]
for child in model_child:
  if type(child)==nn.Conv2d:
    no_of_layers+=1
    conv_layers.append(child)
  elif type(child)==nn.Sequential:
    for layer in child.children():
      if type(layer)==nn.Conv2d:
        no_of_layers+=1
        conv_layers.append(layer)

img = example_data
results = [conv_layers[0](img)]
for i in range(1, len(conv_layers)):
    results.append(conv_layers[i](results[-1]))
outputs = results

for num_layer in range(len(outputs)):
    plt.figure(figsize=(50, 10))
    layer_viz = outputs[num_layer][0, :, :, :]
    layer_viz = layer_viz.data
    print(num_layer+1)
    for i, filter in enumerate(layer_viz):
        if i == 16: 
            break
        plt.subplot(2, 8, i + 1)
        plt.imshow(filter, cmap='gray')
        plt.axis("off")
    plt.show()
    plt.close()